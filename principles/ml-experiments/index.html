<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>ML Experiments - Systology</title><meta name=description content="Reproducibility, resource-awareness, and lightweight MLOps."><link rel=canonical href=https://sambyte.net/systology/principles/ml-experiments/><link rel=icon href=/systology/favicon.svg type=image/svg+xml><meta name=robots content="index, follow"><script>try{localStorage.getItem("theme")==="dark"&&document.documentElement.setAttribute("data-theme","dark")}catch{}document.documentElement.setAttribute("data-loading",""),requestAnimationFrame(function(){requestAnimationFrame(function(){document.documentElement.removeAttribute("data-loading")})})</script><style>html{background:#fff;color:#0f1724}html[data-theme=dark]{background:#0f1724;color:#e2e8f0}html[data-loading] *{transition:none!important}</style><link rel=stylesheet href=/systology/css/styles.css><link rel=stylesheet href=/systology/css/syntax.css><link rel=stylesheet href=/systology/css/search.css></head><body><header class=site-header role=banner><div class="container header-inner"><a class=brand href=/systology/ aria-label=Systology><img src=/systology/favicon.svg alt class=logo-icon> Systology</a><nav class=site-nav role=navigation aria-label="Main navigation"><button class=search-toggle data-open-search aria-label=Search>
<svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="11" cy="11" r="8"/><line x1="21" y1="21" x2="16.65" y2="16.65"/></svg>
</button>
<button class=theme-toggle id=theme-toggle aria-label="Toggle dark mode">
<svg class="icon-moon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg class="icon-sun" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></nav></div></header><main id=content class="container prose"><article><header><div class=title-group><h1>ML Experiments</h1></div><h2>Reproducibility, resource-awareness, and lightweight MLOps.</h2><div class=tags><span>Tags:</span>
<a class=badge href=/systology/tags/ml/>ml</a></div></header><section><h2 id=reproducibility>Reproducibility</h2><p>Pin all dependencies (including minor versions), record random seeds, dataset versions, and hardware configs, and use Docker for consistent environments. A non-reproducible result is just noise.</p><p>Create a <code>requirements.lock</code> (or <code>poetry.lock</code>, <code>uv.lock</code>) that captures exact versions. In your training script, log: Python version, CUDA version, GPU model, random seeds for Python/NumPy/PyTorch, dataset commit hash or version tag, and all hyperparameters. Store this metadata alongside the model checkpoint. When someone says &ldquo;I can&rsquo;t reproduce your results,&rdquo; you should be able to hand them a single config file that recreates the exact environment.</p><p>See how <a href=https://sambyte.net/systology/deep-dives/ai-ml-workshop/>AI/ML Workshop</a> approaches reproducibility with environment management and dependency pinning for ML examples.</p><p><strong>Anti-pattern ‚Äî &ldquo;Works on My Machine&rdquo; ML:</strong> Training a model without recording the environment or seed, then being unable to reproduce the result. Worse: publishing results you can&rsquo;t reproduce. Every ML paper retraction and every &ldquo;model stopped working after re-training&rdquo; incident traces back to reproducibility gaps. Pin everything.</p><h2 id=resource-aware-design>Resource-aware Design</h2><p>Provide CPU/GPU fallbacks and design examples to run on modest hardware with smaller models or techniques like LoRA. Accessibility determines community engagement; gate-keeping on expensive hardware kills adoption.</p><p>Structure your code with a resource-aware configuration: <code>device: auto | cpu | cuda | mps</code>, <code>model_size: small | medium | large</code>, <code>precision: fp32 | fp16 | int8</code>. Auto-detect available hardware and select appropriate defaults. For GPU-heavy training, support gradient checkpointing and mixed precision to reduce VRAM requirements. Provide a &ldquo;lite&rdquo; mode that runs on a laptop&rsquo;s CPU in reasonable time.</p><p><strong>Anti-pattern ‚Äî &ldquo;Requires 8x A100&rdquo; Examples:</strong> Publishing ML examples that only work on enterprise-grade hardware. Most learners and contributors have a laptop with maybe one GPU. If your example requires $50k of hardware to even start, you&rsquo;ve excluded 99% of your potential community. Provide scaled-down configurations that run in minutes on a CPU.</p><h2 id=deterministic-evaluation>Deterministic Evaluation</h2><p>Use fixed train/test/validation splits with reproducible shuffling and implement deterministic metrics. Variability in results makes it hard to know what actual changes you&rsquo;re measuring.</p><p>Lock your data splits by either saving split indices explicitly or using a deterministic hash-based split (<code>hash(id) % 10 &lt; 8</code> for 80/20 train/test). Set <code>torch.use_deterministic_algorithms(True)</code> in PyTorch or equivalent settings in your framework. When comparing experiments, statistical significance testing (paired t-tests, bootstrap confidence intervals) tells you whether a 0.3% accuracy improvement is real or noise.</p><p><strong>Anti-pattern ‚Äî Random Split, Random Seed:</strong> Re-splitting data and re-seeding randomness for each experiment run. You observe a 2% improvement but can&rsquo;t tell if it&rsquo;s from your code change or from a lucky split. Comparing experiments requires controlled variables‚Äîthe data split and seed should be among the most tightly controlled.</p><h2 id=artifact-management>Artifact Management</h2><p>Version model checkpoints, tokenizers, and datasets with checksums for integrity and use structured naming conventions for easy retrieval. Artifact management is unglamorous but critical for replayability.</p><p>Use a naming convention like <code>{model_name}/{version}/{timestamp}/</code> and store a <code>metadata.json</code> alongside each checkpoint containing training config, metrics, dataset version, and parent checkpoint (if fine-tuned). Tools like MLflow, W&amp;B, or even a simple S3 bucket with consistent naming provide the backbone. The key requirement: given any deployed model, you can trace back to the exact training data, code, and config that produced it.</p><p><strong>Anti-pattern ‚Äî &ldquo;model_final_v2_FINAL_use_this_one.pt&rdquo;:</strong> Saving checkpoints with ad-hoc names and no metadata. Within a week you can&rsquo;t remember which one is which, what hyperparameters produced it, or what dataset it was trained on. Structured naming with automated metadata capture prevents this.</p><h2 id=profiling-and-benchmarking>Profiling and Benchmarking</h2><p>Measure wall-clock time, memory, and accelerator utilization rather than guessing where bottlenecks are. Automate common micro-benchmarks to catch regressions early.</p><p>Use <code>torch.profiler</code> or <code>nvidia-smi dmon</code> to identify whether you&rsquo;re GPU-bound (high utilization, training is compute-limited), data-bound (low utilization, data loading is the bottleneck), or memory-bound (frequent OOMs or swapping). Common fixes for data-bound training: increase <code>num_workers</code> in DataLoader, use memory-mapped datasets, or pre-tokenize/pre-process offline.</p><p>See the <a href=https://sambyte.net/systology/principles/algorithms-performance/>Algorithms & Performance</a> principles for general profiling-driven optimization guidance that applies to ML workloads.</p><p><strong>Anti-pattern ‚Äî Blind Batch Size Tuning:</strong> Increasing batch size to &ldquo;speed up training&rdquo; without profiling. If you&rsquo;re data-bound, a larger batch size just increases the wait time per step. If you&rsquo;re memory-bound, you OOM. Profile first, then adjust the right knob.</p><h2 id=lightweight-mlops>Lightweight MLOps</h2><p>Start with simple reproducible scripts before adding complex pipelines‚ÄîYAGNI applies to infrastructure. Automate smoke tests in CI and use tools like MLflow for lightweight tracking without enterprise overhead.</p><p>The progression should be: (1) a single training script with argparse and JSON config, (2) add MLflow/W&amp;B tracking when you have more than 5 experiments to compare, (3) add automated evaluation in CI when you have regression test datasets, (4) add pipeline orchestration (Airflow, Prefect) only when you have recurring training jobs. Most teams jump to step 4 on day one and drown in infrastructure complexity.</p><p><strong>Anti-pattern ‚Äî Kubernetes on Day One:</strong> Deploying Kubeflow, Airflow, and a feature store before you have a working training script. Infrastructure complexity should follow experiment complexity, not precede it. If you&rsquo;re running 3 experiments a month from a Jupyter notebook, you don&rsquo;t need a pipeline orchestrator‚Äîyou need a well-organized script with config files.</p><p>See the <a href=https://sambyte.net/systology/designs/model-serving/>Model Serving</a> design for when you do need production-grade ML infrastructure: model versioning, canary deployment, and A/B testing at scale.</p><h2 id=privacy--data-handling>Privacy & Data Handling</h2><p>Avoid including sensitive or personal data in examples and provide synthetic or public datasets. Examples are code too; treat privacy seriously from the start.</p><p>Use established public datasets (ImageNet, COCO, WikiText) or generate synthetic data for examples and tutorials. If your project involves personal data (medical images, user text), provide clear documentation on data handling: where it&rsquo;s stored, who has access, how long it&rsquo;s retained, and how to delete it. Include a <code>data_card.md</code> that documents dataset provenance, demographics, and known biases.</p><p>See the <a href=https://sambyte.net/systology/principles/privacy-agents/>Privacy & Agents</a> principles for comprehensive guidance on data minimization, consent, and audit logging.</p><p><strong>Anti-pattern ‚Äî PII in Training Data:</strong> Including personally identifiable information (names, emails, addresses, faces) in training datasets without anonymization. Models can memorize and regurgitate PII, creating legal liability and ethical violations. Anonymize, aggregate, or use synthetic data for development.</p><h2 id=education-first-examples>Education-first Examples</h2><p>Keep code minimal and well-commented, structure examples to be expandable, and explain design tradeoffs. Good examples are investments that multiply through the community.</p><p>Each example should have: (1) a README explaining what it demonstrates and what to expect, (2) a single-command run instruction (<code>python train.py --config examples/config.yaml</code>), (3) expected output or metrics so the user knows it worked, and (4) &ldquo;next steps&rdquo; pointing to more advanced configurations. Optimize for the reader&rsquo;s first 15 minutes‚Äîif they can&rsquo;t get a result in that time, they&rsquo;ll abandon the project.</p><h2 id=foundational-theory--practice>Foundational Theory & Practice</h2><p>Build strong foundations in supervised/unsupervised learning, neural networks, and optimization. Understanding math underpinnings means informed implementation choices instead of cargo-cult coding.</p><p>Study the fundamentals: gradient descent mechanics, loss function design, regularization theory, bias-variance tradeoff, attention mechanisms. When you understand <em>why</em> learning rate warmup helps transformers or <em>why</em> batch normalization stabilizes training, you can debug training failures from first principles rather than blindly trying Stack Overflow suggestions.</p><p><strong>Anti-pattern ‚Äî Copy-Paste ML:</strong> Copying training loops from tutorials without understanding the components. When training diverges, you have no mental model for diagnosis‚Äîis it the learning rate, the loss function, the data, or a bug? Foundational understanding turns &ldquo;it doesn&rsquo;t work&rdquo; into &ldquo;the loss is NaN because gradients exploded due to an unscaled learning rate with this optimizer.&rdquo;</p><h2 id=decision-framework>Decision Framework</h2><p>Choose your ML experimentation pattern based on the stage of the model lifecycle:</p><table><thead><tr><th style=text-align:left>If you need&mldr;</th><th style=text-align:left>&mldr;choose this</th><th style=text-align:left>because&mldr;</th></tr></thead><tbody><tr><td style=text-align:left><strong>Rapid Iteration</strong></td><td style=text-align:left>Notebook-based Trials</td><td style=text-align:left>Lowest friction for exploring data and testing initial ideas.</td></tr><tr><td style=text-align:left><strong>Production Stability</strong></td><td style=text-align:left>Scripted Training Jobs</td><td style=text-align:left>Ensures reproducibility through versioned code and artifacts.</td></tr><tr><td style=text-align:left><strong>Model Comparison</strong></td><td style=text-align:left>Feature Store / Registry</td><td style=text-align:left>Provides a single source of truth for features and model performance.</td></tr><tr><td style=text-align:left><strong>Low Overfitting</strong></td><td style=text-align:left>Automated Validation</td><td style=text-align:left>Prevents human bias from leaking into model evaluation metrics.</td></tr></tbody></table><p><strong>Decision Heuristic:</strong> &ldquo;Choose <strong>Versioned Artifacts</strong> over raw notebooks. An experiment is only as valuable as its ability to be reproduced exactly.&rdquo;</p></section><aside class=related><h3>Related</h3><ul><li><a href=/systology/deep-dives/ai-ml-workshop/>AI/ML Workshop</a>
<span class=related-type><small class=label-tag>tag</small></span><br><small class=muted>Practical, reproducible ML examples (PyTorch/Hugging Face/NumPy) with MPS-aware benchmarks and experiment hygiene for local hardware.</small></li><li><a href=/systology/designs/feature-etl/>ETL Pipeline for ML Features</a>
<span class=related-type><small class=label-tag>tag</small></span><br><small class=muted>Robust ETL pipeline for deterministic, reproducible ML feature generation from diverse sources, with idempotence and scale in mind.</small></li><li><a href=/systology/designs/federated-learning/>Privacy-Preserving Federated Learning Platform</a>
<span class=related-type><small class=label-tag>tag</small></span><br><small class=muted>Platform design for federated learning that trains across devices without sharing raw data, with secure aggregation and privacy safeguards.</small></li><li><a href=/systology/deep-dives/ragchain/>Ragchain</a>
<span class=related-type><small class=label-tag>tag</small></span><br><small class=muted>Local RAG stack (Chroma + Ollama) for private, reproducible retrieval and LLM usage; focuses on hybrid retrieval, index versioning, and evaluation.</small></li></ul></aside></article></main><footer class=site-footer role=contentinfo><div class="container footer-inner"><p class=copyright>&copy; 2026 Systology. All rights reserved.</p><div class=social-links><a href=https://github.com/huangsam target=_blank rel="noopener noreferrer" aria-label=GitHub><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
</a><a href=http://linkedin.com/in/sambyte target=_blank rel="noopener noreferrer" aria-label=LinkedIn><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon-linkedin"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></a></div></div></footer><div id=site-search-modal class=site-search-modal-container style=display:none><div class=site-search-overlay data-close-search></div><div class=site-search-modal><div class=site-search-header><div class=site-search-input-wrapper><span class=site-search-icon><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="11" cy="11" r="8"/><line x1="21" y1="21" x2="16.65" y2="16.65"/></svg>
</span><input type=text class=site-search-input id=site-search-input placeholder="Search designs, principles, deep dives..." aria-label=Search autocomplete=off>
<button class=site-search-close data-close-search>&#215;</button></div></div><div class=site-search-body><div id=site-search-default class=site-search-default><div class=site-search-quick-links><a href=/systology/categories/ class=site-search-cta><span class=site-search-cta-icon>üìÇ</span>
<span class=site-search-cta-text>All Categories</span>
<span class=site-search-cta-arrow>‚Üí</span>
</a><a href=/systology/tags/ class=site-search-cta><span class=site-search-cta-icon>üè∑Ô∏è</span>
<span class=site-search-cta-text>All Tags</span>
<span class=site-search-cta-arrow>‚Üí</span></a></div></div><div id=site-search-results-list style=display:none></div></div></div></div><script>document.addEventListener("DOMContentLoaded",function(){let i=null,o=null;const t=document.getElementById("site-search-modal"),n=document.getElementById("site-search-input"),s=document.getElementById("site-search-default"),e=document.getElementById("site-search-results-list"),d=document.querySelectorAll("[data-close-search]"),h=document.querySelectorAll("[data-open-search]");if(!t)return;document.body.appendChild(t);let l=!1;function u(){if(l)return;fetch("/systology/search-index.json").then(e=>e.json()).then(e=>{i=e.documents,l=!0}).catch(e=>console.error("Failed to load search index:",e))}function r(){u(),t.style.display="flex",document.body.style.overflow="hidden",setTimeout(()=>{n.focus(),n.value.trim()?c(n.value):(s.style.display="block",e.style.display="none")},50)}function a(){t.style.display="none",document.body.style.overflow="",n.value="",e.innerHTML="",s.style.display="block",e.style.display="none"}h.forEach(e=>{e.addEventListener("click",e=>{e.preventDefault(),r()})}),d.forEach(e=>{e.addEventListener("click",a)});function c(t){if(!i)return;if(!t.trim()){s.style.display="block",e.style.display="none",e.innerHTML="";return}s.style.display="none",e.style.display="block",t=t.toLowerCase();const n=i.filter(e=>{const n=e.content.toLowerCase(),s=e.title.toLowerCase(),o=(e.tags||[]).join(" ").toLowerCase();return n.includes(t)||s.includes(t)}).slice(0,15);n.length===0?e.innerHTML='<p class="site-search-no-results">No results found.</p>':e.innerHTML=n.map(e=>`
        <a href="${e.url}" class="site-search-result">
          <div class="site-search-result-title">${e.title}</div>
          <div class="site-search-result-preview">${e.preview}</div>
          <div class="site-search-result-meta">
            <span class="site-search-badge-category">${e.category}</span>
            ${e.tags.map(e=>`<span class="site-search-badge">${e}</span>`).join("")}
          </div>
        </a>
      `).join("")}n.addEventListener("input",function(e){o&&clearTimeout(o),o=setTimeout(()=>{c(e.target.value)},300)}),document.addEventListener("keydown",function(e){(e.metaKey||e.ctrlKey)&&e.key==="k"&&(e.preventDefault(),t.style.display==="none"||t.style.display===""?r():a()),e.key==="Escape"&&t.style.display==="flex"&&a()})})</script><script>document.addEventListener("DOMContentLoaded",()=>{const t=document.querySelectorAll(".pseudocode-toggle"),n=document.querySelectorAll(".pseudocode-modal-close"),s=document.querySelectorAll(".pseudocode-modal-overlay");function o(e){const t=document.getElementById(e);if(!t)return;t.classList.add("active"),t.setAttribute("aria-hidden","false"),document.body.style.overflow="hidden";const n=t.querySelector(".pseudocode-modal-close");n&&n.focus()}function e(e){if(!e)return;e.classList.remove("active"),e.setAttribute("aria-hidden","true"),document.body.style.overflow="";const t=document.querySelector(`.pseudocode-toggle[aria-controls="${e.id}"]`);t&&t.focus()}t.forEach(e=>{e.addEventListener("click",()=>{const t=e.getAttribute("aria-controls");o(t)})}),n.forEach(t=>{t.addEventListener("click",t=>{const n=t.target.closest(".pseudocode-modal");e(n)})}),s.forEach(t=>{t.addEventListener("click",t=>{const n=t.target.closest(".pseudocode-modal");e(n)})}),document.addEventListener("keydown",t=>{if(t.key==="Escape"){const t=document.querySelector(".pseudocode-modal.active");t&&e(t)}})})</script><script src=/systology/js/mermaid.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){window.mermaid&&mermaid.initialize({startOnLoad:!0,theme:"base",securityLevel:"loose",themeVariables:{primaryColor:"#f3f4f6",primaryTextColor:"#0f1724",primaryBorderColor:"#2563eb",lineColor:"#6b7280",secondBkgColor:"#ffffff",tertiaryTextColor:"#6b7280",tertiaryColor:"#e6e9ee",noteBkgColor:"#f0f9ff",noteBorderColor:"#2563eb",fontFamily:'-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif'},flowchart:{useMaxWidth:!0,curve:"linear"},sequence:{useMaxWidth:!0},gantt:{useWidth:0[0]}});var e=document.getElementById("theme-toggle");e&&e.addEventListener("click",function(){var e=document.documentElement.getAttribute("data-theme")==="dark";document.documentElement.setAttribute("data-theme",e?"":"dark");try{localStorage.setItem("theme",e?"light":"dark")}catch{}})})</script></body></html>