<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Model Serving & Inference - Systology</title><meta name=description content="Reliable, low-latency ML inference in production."><link rel=canonical href=https://sambyte.net/systology/principles/model-serving/><link rel=icon href=/systology/favicon.svg type=image/svg+xml><meta name=robots content="index, follow"><script data-cfasync=false>try{localStorage.getItem("theme")==="dark"&&(document.documentElement.setAttribute("data-theme","dark"),document.documentElement.style.colorScheme="dark")}catch{}</script><style>:root{color-scheme:light;--bg:#ffffff;--text:#0f1724;--muted:#6b7280;--accent:#2563eb;--accent-weak:rgba(37, 99, 235, 0.08);--accent-weak-up:rgba(37, 99, 235, 0.15);--border:#e6e9ee;--blockquote-bg:#f8fafc;--radius:10px;--max-width:48rem;--focus:3px rgba(37, 99, 235, 0.18);--link-gap:0.5rem;--gutter:0.75rem;--color-warning:#d97706;--color-success:#059669;--space-nano:0.05rem;--space-micro:0.125rem;--space-xs:0.25rem;--space-xs-plus:0.35rem;--space-sm:0.5rem;--space-sm-plus:0.625rem;--space-md:0.75rem;--space-md-plus:0.875rem;--space-lg:1rem;--space-lg-plus:1.1rem;--space-xl:1.25rem;--space-2xl:1.5rem;--space-3xl:2rem;--space-3xl-plus:2.25rem;--space-4xl:2.5rem}[data-theme=dark]{color-scheme:dark;--bg:#0f1724;--text:#e2e8f0;--muted:#94a3b8;--accent:#60a5fa;--accent-weak:rgba(96, 165, 250, 0.1);--accent-weak-up:rgba(96, 165, 250, 0.2);--border:#1e293b;--blockquote-bg:#1a2332;--focus:3px rgba(96, 165, 250, 0.25);--color-warning:#fbbf24;--color-success:#34d399}*{box-sizing:border-box}body{margin:0;background:var(--bg);color:var(--text);font-family:-apple-system,BlinkMacSystemFont,segoe ui,Roboto,helvetica neue,Arial,sans-serif;line-height:1.75;font-size:16px;-webkit-font-smoothing:antialiased;text-rendering:optimizeLegibility;overflow-anchor:none;min-height:100svh;display:grid;grid-template-rows:auto 1fr auto}.container{width:100%;max-width:var(--max-width);margin:0 auto;padding:0 var(--gutter)}main.container{padding-top:var(--space-lg);padding-bottom:var(--space-2xl)}:focus-visible{outline:var(--focus);outline-offset:var(--space-xs)}.theme-toggle{display:inline-flex;align-items:center;justify-content:center;width:var(--space-3xl);height:var(--space-3xl);padding:0;border:1px solid var(--border);border-radius:8px;background:0 0;color:var(--muted);cursor:pointer}.theme-toggle:hover,.theme-toggle:focus-visible{color:var(--accent);border-color:var(--accent);background:var(--accent-weak)}.theme-toggle svg{width:var(--space-lg-plus);height:var(--space-lg-plus)}.theme-toggle .icon-sun{display:none}.theme-toggle .icon-moon{display:block}[data-theme=dark] .theme-toggle .icon-sun{display:block}[data-theme=dark] .theme-toggle .icon-moon{display:none}.pagination{display:flex;justify-content:center;gap:var(--space-lg);margin:var(--space-3xl)0 var(--space-lg)}.pagination a{display:inline-flex;align-items:center;padding:var(--space-sm)var(--space-xl);border:1px solid var(--border);border-radius:6px;color:var(--accent);text-decoration:none;font-size:.95rem;font-weight:500}.pagination a:hover,.pagination a:focus-visible{background:var(--accent-weak);border-color:var(--accent);box-shadow:0 2px 8px rgba(37,99,235,8%)}.card,.post-card{background:linear-gradient(0deg,rgba(0,0,0,1%),rgba(0,0,0,1%));border:1px solid var(--border);border-radius:12px}.card{padding:var(--space-lg)}.post-card{padding:var(--space-xl);display:flex;flex-direction:column;gap:var(--space-md)}.post-card h3{margin:0;font-size:1.1rem;line-height:1.3}.post-card h3 a{text-decoration:none}.post-card h3 a:hover{text-decoration:underline}.post-card .summary{margin:0;color:var(--text);font-size:.95rem;line-height:1.5}.posts-grid{display:grid;grid-template-columns:repeat(auto-fill,minmax(320px,1fr));gap:var(--space-2xl);margin:var(--space-2xl)0}.badge{display:inline-flex;align-items:center;gap:var(--space-xs);padding:var(--space-xs).625rem;background:var(--accent-weak);border:1px solid rgba(37,99,235,.2);border-radius:6px;color:var(--accent);text-decoration:none;font-size:.9rem;font-weight:500}.title-group{display:flex;align-items:center;flex-wrap:wrap;gap:var(--space-lg)}.title-group>*{margin:var(--space-sm)0}.title-group .draft-badge,.title-group .link-pill{font-size:.75rem}.badge:hover,.badge:focus{background:rgba(37,99,235,.15);border-color:var(--accent)}.draft-badge{display:inline-flex;align-items:center;padding:var(--space-micro)var(--space-sm);background:rgba(217,119,6,.1);border:1px solid rgba(217,119,6,.3);border-radius:4px;color:var(--color-warning);font-size:.75rem;font-weight:700;text-transform:uppercase;letter-spacing:.05em}[data-theme=dark] .draft-badge{background:rgba(251,191,36,.1);border-color:rgba(251,191,36,.3)}.link-pill{display:inline-flex;align-items:center;padding:var(--space-micro)var(--space-sm);background:var(--accent-weak);border:1px solid rgba(37,99,235,.2);border-radius:4px;color:var(--accent);text-decoration:none;font-size:.75rem;font-weight:700;letter-spacing:.05em}.link-pill:hover,.link-pill:focus{background:rgba(37,99,235,.15);border-color:var(--accent)}.term-pill{display:inline-flex;align-items:center;gap:var(--space-sm);padding:var(--space-sm)var(--space-md-plus);background:var(--bg);border:1px solid var(--border);border-radius:var(--radius);text-decoration:none;color:var(--text);font-size:.95rem;font-weight:500}.term-pill:hover,.term-pill:focus-visible{border-color:var(--accent);background:var(--accent-weak);transform:translateY(-1px);box-shadow:0 4px 12px rgba(37,99,235,8%)}.term-pill .count{font-size:.8rem;background:var(--bg);color:var(--muted);padding:var(--space-micro)var(--space-sm);border-radius:6px;border:1px solid var(--border)}.term-pill:hover .count{border-color:rgba(37,99,235,.2);color:var(--accent)}.terms-pills{display:flex;flex-wrap:wrap;gap:var(--space-md);margin:var(--space-3xl)0}.label-tag,.label-cat{padding:var(--space-nano)var(--space-xs-plus);border-radius:4px;font-size:.7rem;font-weight:600;text-transform:uppercase;letter-spacing:.02em}.label-tag{background:var(--accent-weak);color:var(--accent);border:1px solid rgba(37,99,235,.2)}.label-cat{background:rgba(5,150,105,.1);color:var(--color-success);border:1px solid rgba(5,150,105,.2)}[data-theme=dark] .label-cat{background:rgba(52,211,153,.1);border:1px solid rgba(52,211,153,.2)}.prose h1{font-size:2rem;line-height:1.05}.prose h2{font-size:1.5rem}.prose h3{font-size:1.15rem}.prose p{margin:.6rem 0}.prose ul,.prose ol{margin:var(--space-md)0}.prose li{margin-bottom:var(--space-sm);padding-left:var(--space-xs)}.prose a{color:var(--accent);text-decoration:underline;text-underline-offset:3px}.prose a.term-pill{text-decoration:none}.prose img{max-width:100%;height:auto;border-radius:8px;display:block;margin:var(--space-md)0}code{background:rgba(37,99,235,8%);padding:.15rem var(--space-xs-plus);border-radius:6px;border:1px solid rgba(37,99,235,.15);font-size:.94em;font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,roboto mono,courier new,monospace}pre{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,roboto mono,courier new,monospace;padding:var(--space-lg);border-radius:var(--radius);background:var(--bg);border:1px solid var(--border);color:var(--text);overflow:auto;margin:var(--space-lg)0;box-shadow:0 2px 8px rgba(0,0,0,4%)}pre code{background:0 0;padding:0;color:inherit;border:none}[data-theme=dark] pre{background:var(--blockquote-bg);border-color:var(--border);color:var(--text)}[data-theme=dark] code{background:var(--accent-weak);border-color:var(--accent-weak-up)}blockquote{margin:var(--space-lg)0;padding:.6rem var(--space-lg);border-left:4px solid var(--border);background:var(--blockquote-bg);color:var(--muted);border-radius:6px}table{width:100%;border-collapse:collapse;margin:var(--space-lg)0;font-size:.95rem}th,td{padding:var(--space-sm).75rem;border-bottom:1px solid var(--border);text-align:left}th{color:var(--muted);font-weight:600}.site-header{border-bottom:1px solid var(--border);background:0 0}.site-header .container{display:flex;align-items:center;justify-content:space-between;gap:var(--space-lg);padding-top:var(--space-lg);padding-bottom:var(--space-lg)}.brand{font-weight:700;font-size:1.125rem;color:var(--text);text-decoration:none;display:flex;align-items:center;gap:var(--space-sm)}.logo-icon{width:1.5rem;height:1.5rem}.site-nav{display:flex;gap:var(--link-gap);align-items:center}.site-nav a{color:var(--muted);text-decoration:none;font-size:.95rem;padding:var(--space-xs).375rem;border-radius:6px}.site-nav a:hover,.site-nav a:focus{color:var(--accent);background:var(--accent-weak);outline:transparent}.site-footer{border-top:1px solid var(--border);color:var(--muted);font-size:.95rem;padding:var(--space-lg)0 var(--space-2xl)}.footer-inner{display:flex;justify-content:space-between;align-items:center;gap:var(--space-lg)}.footer-inner .copyright{margin:0}.social-links{display:flex;gap:var(--space-sm);align-items:center}.social-links a{color:var(--muted);padding:var(--space-xs).375rem;border-radius:6px;display:flex;align-items:center;justify-content:center}.social-links a:hover,.social-links a:focus{color:var(--accent);background:var(--accent-weak);transform:translateY(-1px)}.prose article>header{margin-bottom:var(--space-lg)}.prose article>header h2{margin:.25rem 0 .75rem;font-weight:600;font-size:1.125rem}.prose article>header div.tags{margin:var(--space-sm)0}div.tags{display:flex;flex-wrap:wrap;gap:var(--space-md);align-items:center;margin:var(--space-md)0}div.tags>span{font-weight:600;color:var(--text)}span.muted{margin-left:.125rem}.mermaid{margin:var(--space-2xl)0;padding:var(--space-lg);background:var(--bg);border:1px solid var(--border);border-radius:var(--radius);overflow:auto}.mermaid svg{max-width:100%;height:auto;display:block;margin:0 auto}.mermaid .edgePath .path{stroke:var(--accent);stroke-width:2}.mermaid .flowchart-link{stroke:var(--muted);stroke-width:1.5}.mermaid text{fill:var(--text);font-family:inherit}[data-theme=dark] .mermaid{background:var(--blockquote-bg);border-color:var(--border)}[data-theme=dark] .mermaid .flowchart-link{stroke:var(--text)!important}[data-theme=dark] .mermaid .marker{stroke:var(--text)!important;fill:var(--text)!important}.related{margin-top:var(--space-4xl);padding-top:var(--space-2xl);border-top:1px solid var(--border)}.related h3{font-size:1.05rem;margin:0 0 .75rem;color:var(--muted);font-weight:600;letter-spacing:.02em;text-transform:uppercase}.related ul{list-style:none;padding:0;margin:0;display:grid;gap:var(--space-sm)}.related li{padding:var(--space-sm)0}.related a{font-weight:500;text-decoration:none;color:var(--accent)}.related a:hover{text-decoration:underline}.related .muted{color:var(--muted);font-size:.88rem}.related-type{display:inline-flex;gap:var(--space-sm);margin-left:var(--space-sm);vertical-align:middle}.listing{list-style:none;padding:0;margin:var(--space-2xl)0}.listing li{padding:.625rem 0;border-bottom:1px solid var(--border)}.listing li:last-child{border-bottom:none}.listing a{font-weight:500}.listing .draft-badge{margin-left:var(--space-sm)}.meta{color:var(--muted);font-size:.9rem}@media(max-width:640px){:root{--gutter:var(--space-md)}.brand{font-size:var(--space-lg)}.logo-icon{width:var(--space-xl);height:var(--space-xl)}main.container{padding-top:var(--space-sm);padding-bottom:var(--space-sm)}.footer-inner{flex-direction:column;justify-content:center;gap:var(--space-md)}}@media(min-width:641px) and (max-width:700px){:root{--gutter:var(--space-xl)}}.pseudocode-container{margin:var(--space-lg)0}.pseudocode-toggle{display:inline-flex;align-items:center;gap:var(--space-sm);padding:var(--space-sm)var(--space-lg);background:var(--accent-weak);border:1px solid rgba(37,99,235,.2);border-radius:var(--radius);color:var(--accent);font-weight:500;cursor:pointer}.pseudocode-toggle:hover,.pseudocode-toggle:focus-visible{background:var(--accent-weak-up);border-color:var(--accent);transform:translateY(-1px)}[data-theme=dark] .pseudocode-toggle{border:1px solid rgba(96,165,250,.2)}.pseudocode-modal{display:none;position:fixed;inset:0;z-index:1000;align-items:center;justify-content:center}.pseudocode-modal.active{display:flex}.pseudocode-modal-overlay{position:absolute;inset:0;background:rgba(15,23,36,.5);backdrop-filter:blur(8px);-webkit-backdrop-filter:blur(8px);transition:opacity .2s ease}[data-theme=dark] .pseudocode-modal-overlay{background:rgba(0,0,0,.6)}.pseudocode-modal-content{position:relative;width:100%;max-width:800px;max-height:85vh;margin:0 var(--space-md);background:var(--bg);border:1px solid var(--border);border-radius:12px;box-shadow:0 20px 25px -5px rgba(0,0,0,.1),0 10px 10px -5px rgba(0,0,0,4%);display:flex;flex-direction:column;overflow:hidden;z-index:1001;animation:modalIn .2s cubic-bezier(.16,1,.3,1)}[data-theme=dark] .pseudocode-modal-content{box-shadow:0 20px 25px -5px rgba(0,0,0,.5),0 10px 10px -5px rgba(0,0,0,.25)}@keyframes modalIn{from{opacity:0;transform:scale(.95)translateY(10px)}to{opacity:1;transform:scale(1)translateY(0)}}.pseudocode-modal-header{display:flex;align-items:center;justify-content:space-between;padding:var(--space-md)var(--space-xl);border-bottom:1px solid var(--border);background:var(--bg)}.pseudocode-modal-title{margin:0;font-size:1.1rem;font-weight:600;color:var(--text);overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.pseudocode-modal-close{display:flex;align-items:center;justify-content:center;width:32px;height:32px;background:0 0;border:none;border-radius:6px;color:var(--muted);cursor:pointer;padding:0;margin-left:var(--space-md);flex-shrink:0}.pseudocode-modal-close:hover,.pseudocode-modal-close:focus-visible{background:rgba(239,68,68,.1);color:#ef4444}.pseudocode-modal-body{padding:0 var(--space-xl)var(--space-xl);overflow-y:auto;overscroll-behavior:contain;font-size:.85rem}.pseudocode-modal-body pre{margin:var(--space-md)0}.bg{color:#fff;background-color:#000}.chroma{color:#fff;background-color:#000;-webkit-text-size-adjust:none}.chroma .lnlinks{outline:none;text-decoration:none;color:inherit}.chroma .lntd{vertical-align:top;padding:0;margin:0;border:0}.chroma .lntable{border-spacing:0;padding:0;margin:0;border:0}.chroma .hl{background-color:#191919}.chroma .lnt{white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f}.chroma .ln{white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f}.chroma .line{display:flex}.chroma .k{color:#b6a0ff}.chroma .kc{color:#00bcff}.chroma .kd{color:#b6a0ff}.chroma .kn{color:#b6a0ff}.chroma .kp{color:#b6a0ff}.chroma .kr{color:#b6a0ff}.chroma .kt{color:#6ae4b9}.chroma .nb{color:#f78fe7}.chroma .bp{color:#f78fe7}.chroma .nv{color:#00d3d0}.chroma .vc{color:#00d3d0}.chroma .vg{color:#00d3d0}.chroma .vi{color:#00d3d0}.chroma .vm{color:#00d3d0}.chroma .nf{color:#feacd0}.chroma .fm{color:#feacd0}.chroma .l{color:#00bcff}.chroma .ld{color:#00bcff}.chroma .s{color:#79a8ff}.chroma .sa{color:#79a8ff}.chroma .sb{color:#79a8ff}.chroma .sc{color:#79a8ff}.chroma .dl{color:#79a8ff}.chroma .sd{color:#79a8ff}.chroma .s2{color:#79a8ff}.chroma .se{color:#79a8ff}.chroma .sh{color:#79a8ff}.chroma .si{color:#79a8ff}.chroma .sx{color:#79a8ff}.chroma .sr{color:#79a8ff}.chroma .s1{color:#79a8ff}.chroma .ss{color:#79a8ff}.chroma .m{color:#00bcff}.chroma .mb{color:#00bcff}.chroma .mf{color:#00bcff}.chroma .mh{color:#00bcff}.chroma .mi{color:#00bcff}.chroma .il{color:#00bcff}.chroma .mo{color:#00bcff}.chroma .o{color:#00d3d0}.chroma .ow{color:#00d3d0}.chroma .c{color:#a8a8a8}.chroma .ch{color:#a8a8a8}.chroma .cm{color:#a8a8a8}.chroma .c1{color:#a8a8a8}.chroma .cs{color:#a8a8a8}.chroma .cp{color:#a8a8a8}.chroma .cpf{color:#a8a8a8}</style></head><body><header class=site-header role=banner><div class="container header-inner"><a class=brand href=/systology/ aria-label=Systology><img src=/systology/favicon.svg alt class=logo-icon> Systology</a><nav class=site-nav role=navigation aria-label="Main navigation"><button class=theme-toggle onclick='window.location.href="/systology/tags/"' aria-label=Tags>
<svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M20.59 13.41l-7.17 7.17a2 2 0 01-2.83.0L2 12V2h10l8.59 8.59a2 2 0 010 2.82z"/><line x1="7" y1="7" x2="7.01" y2="7"/></svg>
</button>
<button class=theme-toggle onclick='window.location.href="/systology/categories/"' aria-label=Categories>
<svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M22 19a2 2 0 01-2 2H4a2 2 0 01-2-2V5a2 2 0 012-2h5l2 3h9a2 2 0 012 2z"/></svg>
</button>
<button class=theme-toggle id=theme-toggle aria-label="Toggle dark mode">
<svg class="icon-moon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg class="icon-sun" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></nav></div></header><main id=content class="container prose"><article><header><div class=title-group><h1>Model Serving & Inference</h1></div><h2>Reliable, low-latency ML inference in production.</h2><div class=tags><span>Tags:</span>
<a class=badge href=/systology/tags/ml/>ml</a>
<a class=badge href=/systology/tags/monitoring/>monitoring</a></div></header><section><h2 id=immutable-model-registry>Immutable Model Registry</h2><p>Treat model versions as immutable artifacts—never overwrite a version in place. Store binaries, runtime environments, and a metadata manifest together so any deployed version can be reproduced or rolled back instantly.</p><p>A model registry is a content-addressable store where each entry maps a version identifier to a frozen tuple: <code>(weights_uri, runtime_container_tag, preprocessing_config, training_run_id)</code>. The <code>is_live</code> flag is the only mutable field—everything else is sealed at publish time. When you need to revert a bad rollout, the previous version already exists and is fully self-contained; there&rsquo;s nothing to rebuild. Without immutability, the &ldquo;working version&rdquo; can change underneath you even without a new deployment.</p><p><strong>Anti-pattern — Overwriting <code>latest</code>:</strong> Pushing new weights to the same <code>model_latest.pt</code> path in object storage. Any service that cached the old file now silently uses stale weights, and there&rsquo;s no way to go back if the new version is broken. Use content-addressed versioning (<code>model_v42_sha256abc.pt</code>) and never overwrite past versions.</p><h2 id=micro-batching-for-gpu-throughput>Micro-batching for GPU Throughput</h2><p>Aggregate incoming inference requests over a short time window (5–10 ms) before dispatching a single batched kernel call. This amortizes GPU launch overhead across many requests and dramatically improves throughput without meaningfully impacting tail latency.</p><p>GPU kernel launches have fixed overhead (~50–200 μs) regardless of batch size. A single request processed alone wastes most of that overhead budget. Batching 32 requests together on the same kernel launch increases throughput by 20–30× while adding only the batching window to latency. Tune the window duration and max batch size per model: latency-sensitive models need shorter windows; throughput-oriented models can tolerate larger ones.</p><p><strong>Anti-pattern — Request-per-Kernel:</strong> Dispatching one GPU kernel per incoming request. At 1,000 RPS, you spend more time on kernel launches than actual computation. Micro-batching is the single highest-leverage optimization for GPU inference throughput.</p><h2 id=canary-rollouts-with-metrics-driven-promotion>Canary Rollouts with Metrics-Driven Promotion</h2><p>Route a small fraction of live traffic (5–10%) to a new model version before promoting it fully. Automated promotion decisions should compare latency and accuracy metrics between the canary and stable pools over a validation window.</p><p>Canaries work best when you define promotion criteria upfront: &ldquo;promote if P99 latency is within 10% of baseline and accuracy delta on shadow labels is less than 0.5% for 4 hours.&rdquo; Automated rollback triggers—fires if error rate or latency exceeds thresholds—prevent bad canaries from causing extended incidents. Treat the canary decision as a pipeline stage, not a manual review.</p><div class=mermaid>graph TD
Client --> Gateway
Gateway --> Router[Router<br>Canary Split]
Router -->|5-10% canary| Canary[Canary Pool<br>New Version]
Router -->|90-95% stable| Stable[Stable Pool<br>Current Version]
Canary --> Gate{Metrics Gate}
Gate -->|pass| Promote[Promote to 100%]
Gate -->|fail| Rollback[Rollback]
Stable -.->|on error| Fallback[Fallback Model]
Canary -.->|on error| Fallback</div><p>See the <a href=https://sambyte.net/systology/principles/ml-experiments/>ML Experiments</a> principles for guidance on reproducible model evaluation and artifact versioning that precedes a canary launch.</p><p><strong>Anti-pattern — Big-bang Cutover:</strong> Switching 100% of traffic to a new model version instantaneously. If the new version has a regression, every user is affected immediately. A 5% canary limits blast radius and gives you real-world signal before full commitment.</p><h2 id=fallback--graceful-degradation>Fallback & Graceful Degradation</h2><p>Always have a fallback model that activates automatically on latency spikes or primary failures. A distilled, smaller version of the primary model provides degraded-but-useful inference while preserving SLA compliance.</p><p>Design the fallback to be stateless and fast: a distilled or quantized model loaded permanently in memory, not fetched on demand when things are already broken. Define activation triggers: &ldquo;if P99 latency exceeds 300 ms for 30 consecutive seconds, reroute to fallback.&rdquo; Cached predictions are another valid fallback for workloads with low input cardinality. The goal is: the user gets a result, even if it&rsquo;s less accurate.</p><p><strong>Anti-pattern — No Fallback Path:</strong> Returning errors to users when the primary model is slow or unavailable. For most inference workloads, a degraded response is vastly preferable to an error. Design the &ldquo;what if the GPU pool is saturated?&rdquo; path before you need it.</p><h2 id=gpu-resource-management>GPU Resource Management</h2><p>Choose between GPU sharing and isolation based on latency requirements. Share GPUs across small models to maximize utilization; isolate GPUs for latency-critical paths or large models to eliminate noisy-neighbor effects.</p><p>Use NVIDIA MPS (Multi-Process Service) to share a single GPU across multiple small models with low per-request memory needs—this keeps GPU utilization high. For models with strict P99 SLOs, dedicate a GPU to avoid contention from co-located workloads. Assign GPUs based on model memory footprint at registration time, not at request time, to eliminate scheduling jitter.</p><p><strong>Anti-pattern — One-size-fits-all Sharing:</strong> Co-locating a batch-heavy model and a latency-critical model on the same GPU. The batch job saturates GPU memory and compute, causing the latency-sensitive model to miss its SLO. Segment by latency profile at the infrastructure level.</p><h2 id=eliminate-training-serving-skew>Eliminate Training-Serving Skew</h2><p>Version preprocessing transforms alongside model weights and run them inside the serving pipeline. Skew between training-time and serving-time feature computation is the most common cause of silent accuracy degradation.</p><p>Training-serving skew occurs when the feature vector seen at inference differs from the one the model was trained on—even if the difference is subtle (different normalization constants, different tokenizer version, missing feature imputation). The fix: treat the preprocessing pipeline as part of the model artifact. Bundle it into the model package and test it with the same inputs used during training evaluation.</p><p>See the <a href=https://sambyte.net/systology/principles/data-pipelines/>Data Pipelines</a> principles for guidance on schema evolution and idempotent feature generation that feeds into the serving pipeline.</p><p><strong>Anti-pattern — Separate Preprocessing Repos:</strong> Maintaining training preprocessing in a ML research repo and serving preprocessing in an application repo with no enforced sync. Over time they diverge. The model performs great on offline benchmarks and inexplicably worse in production. Colocate and version them together.</p><h2 id=observability-for-inference>Observability for Inference</h2><p>Log input feature distributions, output confidence scores, and hardware metrics alongside standard latency/error metrics. Distribution drift in inputs is an early warning signal for accuracy degradation before it shows up in labels.</p><p>Emit: <code>inference_latency_p99</code>, <code>batch_fill_ratio</code>, <code>gpu_utilization</code>, <code>model_version</code>, and sampled <code>(input_hash, output_distribution)</code> for each serving replica. Monitor <code>canary_accuracy_delta</code> during rollouts. Alert on GPU memory pressure before it causes OOM evictions. For high-cardinality input spaces, sample at 1–5% to manage storage costs.</p><p>See the <a href=https://sambyte.net/systology/principles/monitoring/>Monitoring & Observability</a> principles for SLO construction and alerting patterns that apply directly to inference services.</p><h2 id=decision-framework>Decision Framework</h2><p>Choose your model serving configuration based on the primary constraint for your workload:</p><table><thead><tr><th style=text-align:left>If you need&mldr;</th><th style=text-align:left>&mldr;choose this</th><th style=text-align:left>because&mldr;</th></tr></thead><tbody><tr><td style=text-align:left><strong>Lowest P99 Latency</strong></td><td style=text-align:left>Dedicated GPU + no sharing</td><td style=text-align:left>Eliminates noisy-neighbor contention; predictable tail latency.</td></tr><tr><td style=text-align:left><strong>Maximum Throughput</strong></td><td style=text-align:left>Micro-batching + shared GPU (MPS)</td><td style=text-align:left>Amortizes kernel launch cost; maximizes GPU utilization.</td></tr><tr><td style=text-align:left><strong>Safe Rollout</strong></td><td style=text-align:left>Canary (5–10%) + metrics gate</td><td style=text-align:left>Limits blast radius; automated promotion prevents human error.</td></tr><tr><td style=text-align:left><strong>Graceful Degradation</strong></td><td style=text-align:left>Distilled fallback model (always warm)</td><td style=text-align:left>Preserves SLA compliance during primary failure; loaded in memory, not fetched on demand.</td></tr><tr><td style=text-align:left><strong>Cost Efficiency</strong></td><td style=text-align:left>Multi-model GPU sharing (MPS)</td><td style=text-align:left>Keeps utilization high for many small models; acceptable when latency SLAs are loose.</td></tr><tr><td style=text-align:left><strong>Accuracy Safety Net</strong></td><td style=text-align:left>Shadow traffic + offline eval before canary</td><td style=text-align:left>Catches regressions on real inputs before any user sees the new model.</td></tr></tbody></table><p><strong>Decision Heuristic:</strong> &ldquo;Choose <strong>dedicated GPU isolation</strong> for latency-critical paths and <strong>micro-batching with shared GPUs</strong> for throughput-oriented workloads. Never sacrifice the fallback path—design it before you need it.&rdquo;</p></section><aside class=related><h3>Related</h3><ul><li><a href=/systology/deep-dives/ai-ml-workshop/>AI/ML Workshop</a>
<span class=related-type><small class=label-tag>tag</small></span><br><small class=muted>Practical, reproducible ML examples (PyTorch/Hugging Face/NumPy) with MPS-aware benchmarks and experiment hygiene for local hardware.</small></li><li><a href=/systology/deep-dives/chowist/>Chowist</a>
<span class=related-type><small class=label-tag>tag</small></span><br><small class=muted>Monolithic Django app for place listings; focus on production hardening: static serving, background jobs, connection pooling, and CI/CD.</small></li><li><a href=/systology/designs/distributed-cache/>Distributed Caching Layer for VCS</a>
<span class=related-type><small class=label-tag>tag</small></span><br><small class=muted>Design a distributed cache to reduce I/O and speed up VCS operations by caching objects and hashes with high concurrency and low latency.</small></li><li><a href=/systology/deep-dives/flink-trial/>Flink Trial</a>
<span class=related-type><small class=label-tag>tag</small></span><br><small class=muted>Streaming analytics demo for simulated IoT events — emphasizes time semantics, state backends, checkpointing, and fault tolerance.</small></li></ul></aside></article></main><footer class=site-footer role=contentinfo><div class="container footer-inner"><p class=copyright>&copy; 2026 Systology. All rights reserved.</p><div class=social-links><a href=/systology/index.xml aria-label="RSS Feed"><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg>
</a><a href=/systology/sitemap.xml aria-label=Sitemap><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect x="3" y="3" width="7" height="7" rx="1"/><rect x="14" y="3" width="7" height="7" rx="1"/><rect x="3" y="14" width="7" height="7" rx="1"/><rect x="14" y="14" width="7" height="7" rx="1"/></svg>
</a><a href=https://github.com/huangsam target=_blank rel="noopener noreferrer" aria-label=GitHub><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
</a><a href=http://linkedin.com/in/sambyte target=_blank rel="noopener noreferrer" aria-label=LinkedIn><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon-linkedin"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></a></div></div></footer><script>document.addEventListener("DOMContentLoaded",()=>{const t=document.querySelectorAll(".pseudocode-toggle"),n=document.querySelectorAll(".pseudocode-modal-close"),s=document.querySelectorAll(".pseudocode-modal-overlay");function o(e){const t=document.getElementById(e);if(!t)return;t.classList.add("active"),t.setAttribute("aria-hidden","false"),document.body.style.overflow="hidden";const n=t.querySelector(".pseudocode-modal-content");n&&(n.setAttribute("tabindex","-1"),n.focus())}function e(e){if(!e)return;e.classList.remove("active"),e.setAttribute("aria-hidden","true"),document.body.style.overflow="";const t=document.querySelector(`.pseudocode-toggle[aria-controls="${e.id}"]`);t&&t.focus()}t.forEach(e=>{e.addEventListener("click",()=>{const t=e.getAttribute("aria-controls");o(t)})}),n.forEach(t=>{t.addEventListener("click",t=>{const n=t.target.closest(".pseudocode-modal");e(n)})}),s.forEach(t=>{t.addEventListener("click",t=>{const n=t.target.closest(".pseudocode-modal");e(n)})}),document.addEventListener("keydown",t=>{if(t.key==="Escape"){const t=document.querySelector(".pseudocode-modal.active");t&&e(t)}})})</script><script src=/systology/js/mermaid.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){window.mermaid&&mermaid.initialize({startOnLoad:!0,theme:"base",securityLevel:"loose",themeVariables:{primaryColor:"#f3f4f6",primaryTextColor:"#0f1724",primaryBorderColor:"#2563eb",lineColor:"#6b7280",secondBkgColor:"#ffffff",tertiaryTextColor:"#6b7280",tertiaryColor:"#e6e9ee",noteBkgColor:"#f0f9ff",noteBorderColor:"#2563eb",fontFamily:'-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif'},flowchart:{useMaxWidth:!0,curve:"linear"},sequence:{useMaxWidth:!0},gantt:{useWidth:0[0]}});var e=document.getElementById("theme-toggle");e&&e.addEventListener("click",function(){var e=document.documentElement.getAttribute("data-theme")==="dark";document.documentElement.setAttribute("data-theme",e?"":"dark");try{localStorage.setItem("theme",e?"light":"dark")}catch{}})})</script></body></html>