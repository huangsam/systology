{"documents": [{"id": "0", "title": "AI/ML Workshop", "description": "AI/ML workshops on model training and evaluation.", "preview": "AI/ML workshops on model training and evaluation.", "tags": ["ml", "privacy"], "category": "deep-dives", "url": "/deep-dives/ai-ml-workshop/", "content": "ai/ml workshop ai/ml workshops on model training and evaluation. practical, reproducible ml examples (pytorch/hugging face/numpy) with mps-aware benchmarks and experiment hygiene for local hardware. ml privacy"}, {"id": "1", "title": "Beam Trial", "description": "Apache Beam for unified batch/streaming pipelines.", "preview": "Apache Beam for unified batch/streaming pipelines.", "tags": ["data-pipelines", "extensibility", "streaming"], "category": "deep-dives", "url": "/deep-dives/beam-trial/", "content": "beam trial apache beam for unified batch/streaming pipelines. minimal apache beam hello world in java/gradle demonstrating pipeline construction, transforms, and directrunner execution for learning beam's core model. data-pipelines extensibility streaming"}, {"id": "2", "title": "Chowist", "description": "Web app for food features with twelve-factor scaling.", "preview": "Web app for food features with twelve-factor scaling.", "tags": ["monitoring", "networking"], "category": "deep-dives", "url": "/deep-dives/chowist/", "content": "chowist web app for food features with twelve-factor scaling. monolithic django app for place listings; focus on production hardening: static serving, background jobs, connection pooling, and ci/cd. monitoring networking"}, {"id": "3", "title": "Flink Trial", "description": "Stream processing with state and fault tolerance.", "preview": "Stream processing with state and fault tolerance.", "tags": ["analytics", "data-pipelines", "monitoring", "streaming"], "category": "deep-dives", "url": "/deep-dives/flink-trial/", "content": "flink trial stream processing with state and fault tolerance. streaming analytics demo for simulated iot events \u2014 emphasizes time semantics, state backends, checkpointing, and fault tolerance. analytics data-pipelines monitoring streaming"}, {"id": "4", "title": "Grit", "description": "VCS implementation with plumbing/porcelain architecture.", "preview": "VCS implementation with plumbing/porcelain architecture.", "tags": ["algorithms", "extensibility", "performance", "rust", "vcs"], "category": "deep-dives", "url": "/deep-dives/grit/", "content": "grit vcs implementation with plumbing/porcelain architecture. from\u2011scratch git implementation in rust focusing on object storage, performance, and plumbing/porcelain command compatibility. algorithms extensibility performance rust vcs"}, {"id": "5", "title": "Mailprune", "description": "Email management tool for data processing.", "preview": "Email management tool for data processing.", "tags": ["data-pipelines", "monitoring", "networking", "privacy", "security"], "category": "deep-dives", "url": "/deep-dives/mailprune/", "content": "mailprune email management tool for data processing. local-first email auditing and cleanup tool that identifies noisy senders and produces privacy-preserving recommendations. data-pipelines monitoring networking privacy security"}, {"id": "6", "title": "Photohaul", "description": "Photo system with media analysis and storage.", "preview": "Photo system with media analysis and storage.", "tags": ["deduplication", "extensibility", "media", "networking"], "category": "deep-dives", "url": "/deep-dives/photohaul/", "content": "photohaul photo system with media analysis and storage. java tool for organizing and migrating large photo collections with deduplication, metadata preservation, and resumable jobs. deduplication extensibility media networking"}, {"id": "7", "title": "Ragchain", "description": "Retrieval-augmented generation with search and ML.", "preview": "Retrieval-augmented generation with search and ML.", "tags": ["ml", "privacy", "retrieval"], "category": "deep-dives", "url": "/deep-dives/ragchain/", "content": "ragchain retrieval-augmented generation with search and ml. local rag stack (chroma + ollama) for private, reproducible retrieval and llm usage; focuses on hybrid retrieval, index versioning, and evaluation. ml privacy retrieval"}, {"id": "8", "title": "Rustoku", "description": "High-performance Sudoku solver in Rust.", "preview": "High-performance Sudoku solver in Rust.", "tags": ["algorithms", "performance", "rust"], "category": "deep-dives", "url": "/deep-dives/rustoku/", "content": "rustoku high-performance sudoku solver in rust. fast sudoku solver and generator in rust using bitmasking and mrv heuristics; emphasizes speed, determinism, and explainable solve traces. algorithms performance rust"}, {"id": "9", "title": "Spark Trial", "description": "Batch processing with ETL workflows.", "preview": "Batch processing with ETL workflows.", "tags": ["data-pipelines", "etl", "monitoring"], "category": "deep-dives", "url": "/deep-dives/spark-trial/", "content": "spark trial batch processing with etl workflows. end-to-end etl example using apache spark for parquet datasets; focuses on schema handling, partitioning, and reproducible aggregation. data-pipelines etl monitoring"}, {"id": "10", "title": "Vidicant", "description": "Video processing for media pipelines.", "preview": "Video processing for media pipelines.", "tags": ["extensibility", "feature-extraction", "media"], "category": "deep-dives", "url": "/deep-dives/vidicant/", "content": "vidicant video processing for media pipelines. cross-platform video/image feature extractor (c++ core, python bindings) for ml preprocessing focusing on throughput, accuracy, and packaging. extensibility feature-extraction media"}, {"id": "11", "title": "VirtuC", "description": "Rust compiler for a C subset targeting LLVM IR.", "preview": "Rust compiler for a C subset targeting LLVM IR.", "tags": ["algorithms", "compiler", "performance", "rust"], "category": "deep-dives", "url": "/deep-dives/virtuc/", "content": "virtuc rust compiler for a c subset targeting llvm ir. rust-implemented compiler for a c subset that emits llvm ir and focuses on ast design, semantic checks, and ir validation for teaching. algorithms compiler performance rust"}, {"id": "12", "title": "xcode-trial", "description": "iOS/macOS development with app architecture.", "preview": "iOS/macOS development with app architecture.", "tags": ["concurrency", "feature-extraction", "media"], "category": "deep-dives", "url": "/deep-dives/xcode-trial/", "content": "xcode-trial ios/macos development with app architecture. multimodal video analysis on macos using avfoundation, vision, and core image \u2014 extracts faces, scenes, colors, motion, audio, and text with json output. concurrency feature-extraction media"}, {"id": "13", "title": "Ad Click Aggregator", "description": "Real-time big data processing for ad events.", "preview": "Real-time big data processing for ad events.", "tags": ["analytics", "streaming"], "category": "designs", "url": "/designs/ad-click-aggregator/", "content": "ad click aggregator real-time big data processing for ad events. design for aggregating ad clicks at massive scale, focusing on deduplication, exactly-once processing, and low-latency reporting. analytics streaming"}, {"id": "14", "title": "Background Job Queue for Big Tasks", "description": "Async job for videos and data processing.", "preview": "Async job for videos and data processing.", "tags": ["concurrency", "distributed-systems", "monitoring", "networking", "queues"], "category": "designs", "url": "/designs/background-job-queue/", "content": "background job queue for big tasks async job for videos and data processing. asynchronous job queue design for resource-heavy tasks (video encoding, data processing) with retries, idempotency, dlq handling, and autoscaling. concurrency distributed-systems monitoring networking queues"}, {"id": "15", "title": "Global CDN Media Serving", "description": "Distributed media delivery worldwide.", "preview": "Distributed media delivery worldwide.", "tags": ["caching", "media", "monitoring", "networking", "performance"], "category": "designs", "url": "/designs/cdn-media/", "content": "global cdn media serving distributed media delivery worldwide. cdn-backed media delivery architecture for low-latency, highly-available global media serving with background upload processing. caching media monitoring networking performance"}, {"id": "16", "title": "Real-Time Collaborative WebApp", "description": "Stateful synchronization for multiplayer web applications.", "preview": "Stateful synchronization for multiplayer web applications.", "tags": ["concurrency", "distributed-systems", "real-time"], "category": "designs", "url": "/designs/collaborative-webapp/", "content": "real-time collaborative webapp stateful synchronization for multiplayer web applications. design for a google docs or figma style application using websockets, operational transformation (ot), or crdts to maintain consistent state among concurrent writers. concurrency distributed-systems real-time"}, {"id": "17", "title": "Distributed Caching Layer for VCS", "description": "Performance optimization for version control.", "preview": "Performance optimization for version control.", "tags": ["algorithms", "caching", "concurrency", "distributed-systems", "monitoring", "performance", "vcs"], "category": "designs", "url": "/designs/distributed-cache/", "content": "distributed caching layer for vcs performance optimization for version control. design a distributed cache to reduce i/o and speed up vcs operations by caching objects and hashes with high concurrency and low latency. algorithms caching concurrency distributed-systems monitoring performance vcs"}, {"id": "18", "title": "ETL Pipeline for ML Features", "description": "Data extraction, transformation, and loading.", "preview": "Data extraction, transformation, and loading.", "tags": ["data-pipelines", "etl", "ml", "monitoring"], "category": "designs", "url": "/designs/feature-etl/", "content": "etl pipeline for ml features data extraction, transformation, and loading. robust etl pipeline for deterministic, reproducible ml feature generation from diverse sources, with idempotence and scale in mind. data-pipelines etl ml monitoring"}, {"id": "19", "title": "Privacy-Preserving Federated Learning Platform", "description": "Distributed learning without data sharing.", "preview": "Distributed learning without data sharing.", "tags": ["algorithms", "distributed-systems", "ml", "privacy"], "category": "designs", "url": "/designs/federated-learning/", "content": "privacy-preserving federated learning platform distributed learning without data sharing. platform design for federated learning that trains across devices without sharing raw data, with secure aggregation and privacy safeguards. algorithms distributed-systems ml privacy"}, {"id": "20", "title": "Flash Sale / Ticketmaster", "description": "High-concurrency inventory management for massive traffic spikes.", "preview": "High-concurrency inventory management for massive traffic spikes.", "tags": ["algorithms", "concurrency", "database", "distributed-systems"], "category": "designs", "url": "/designs/flash-sale/", "content": "flash sale / ticketmaster high-concurrency inventory management for massive traffic spikes. design for handling extreme bursts of traffic where limited inventory must be distributed fairly and consistently under heavy load. algorithms concurrency database distributed-systems"}, {"id": "21", "title": "Privacy-First Identity & Access Management", "description": "Authentication and Authorization gateway with local-first isolation.", "preview": "Authentication and Authorization gateway with local-first isolation.", "tags": ["networking", "privacy", "security"], "category": "designs", "url": "/designs/identity-management/", "content": "privacy-first identity & access management authentication and authorization gateway with local-first isolation. design for an auth0/keycloak-style identity provider focused on oauth2/oidc federation, token lifecycle, and privacy-preserving rbac. networking privacy security"}, {"id": "22", "title": "End-to-End Migration & Deduplication", "description": "Large-scale data migration and dedup.", "preview": "Large-scale data migration and dedup.", "tags": ["deduplication", "networking"], "category": "designs", "url": "/designs/migration-dedup/", "content": "end-to-end migration & deduplication large-scale data migration and dedup. system design for migrating large datasets with deduplication, integrity checks, resumability, and idempotence. deduplication networking"}, {"id": "23", "title": "Scalable Model Serving Inference", "description": "Real-time ML inference at scale.", "preview": "Real-time ML inference at scale.", "tags": ["ml", "monitoring"], "category": "designs", "url": "/designs/model-serving/", "content": "scalable model serving inference real-time ml inference at scale. infrastructure for real-time ml inference with model versioning, autoscaling, and resource-aware fallbacks. ml monitoring"}, {"id": "24", "title": "Notification System", "description": "Scalable multi-channel notification engine for real-time engagement.", "preview": "Scalable multi-channel notification engine for real-time engagement.", "tags": ["distributed-systems", "queues"], "category": "designs", "url": "/designs/notification-system/", "content": "notification system scalable multi-channel notification engine for real-time engagement. design of a high-throughput notification service supporting push, email, and sms with prioritization, rate limiting, and delivery tracking. distributed-systems queues"}, {"id": "25", "title": "Payment System", "description": "Handling global transactions with high reliability and consistency.", "preview": "Handling global transactions with high reliability and consistency.", "tags": ["algorithms", "database", "distributed-systems"], "category": "designs", "url": "/designs/payment-system/", "content": "payment system handling global transactions with high reliability and consistency. design of a scalable payment gateway integration and internal ledger system ensuring idempotency, strict consistency, and failure recovery. algorithms database distributed-systems"}, {"id": "26", "title": "Proximity Service for Maps", "description": "High-performance location-based search using geospatial indexing.", "preview": "High-performance location-based search using geospatial indexing.", "tags": ["algorithms", "caching", "database"], "category": "designs", "url": "/designs/proximity-service/", "content": "proximity service for maps high-performance location-based search using geospatial indexing. design for finding nearby points of interest with low latency, focusing on geospatial data structures like geohashing or quadtrees. algorithms caching database"}, {"id": "27", "title": "Real-Time Analytics Pipeline", "description": "Event stream processing and metrics.", "preview": "Event stream processing and metrics.", "tags": ["analytics", "data-pipelines", "monitoring", "queues", "real-time"], "category": "designs", "url": "/designs/realtime-analytics/", "content": "real-time analytics pipeline event stream processing and metrics. scalable real-time pipeline to ingest and process high-volume user event streams for immediate analytics and dashboards; handles late arrivals and fault tolerance. analytics data-pipelines monitoring queues real-time"}, {"id": "28", "title": "Search & Retrieval Engine", "description": "High-performance document search.", "preview": "High-performance document search.", "tags": ["algorithms", "monitoring", "privacy", "retrieval"], "category": "designs", "url": "/designs/search-retrieval/", "content": "search & retrieval engine high-performance document search. design a high-performance search and retrieval engine for large document/media collections with low-latency ranking and scalable indexing. algorithms monitoring privacy retrieval"}, {"id": "29", "title": "URL Shortener & Pastebin", "description": "Distributed unique ID generation and read-heavy caching.", "preview": "Distributed unique ID generation and read-heavy caching.", "tags": ["caching", "database", "distributed-systems", "networking"], "category": "designs", "url": "/designs/url-shortener/", "content": "url shortener & pastebin distributed unique id generation and read-heavy caching. design for a highly available, read-heavy service bridging short aliases to long urls, focusing on base62 encoding, snowflake ids, and collision avoidance. caching database distributed-systems networking"}, {"id": "30", "title": "Video Transcoding & Streaming Pipeline", "description": "Distributed chunking and transmuxing pipeline for video processing.", "preview": "Distributed chunking and transmuxing pipeline for video processing.", "tags": ["data-pipelines", "distributed-systems", "media", "streaming"], "category": "designs", "url": "/designs/video-transcoding/", "content": "video transcoding & streaming pipeline distributed chunking and transmuxing pipeline for video processing. design for a scalable video ingestion and transcoding system that chunks media, extracts features, and outputs adaptive bitrates using worker pools. data-pipelines distributed-systems media streaming"}, {"id": "31", "title": "Distributed Web Crawler", "description": "High-scale, hostile-network data ingestion and graph traversal.", "preview": "High-scale, hostile-network data ingestion and graph traversal.", "tags": ["caching", "data-pipelines", "distributed-systems", "networking"], "category": "designs", "url": "/designs/web-crawler/", "content": "distributed web crawler high-scale, hostile-network data ingestion and graph traversal. design for a google-scale web crawler focusing on breadth-first search (bfs), dns resolution caching, robots.txt politeness, and handling duplicate or malicious domains. caching data-pipelines distributed-systems networking"}, {"id": "32", "title": "Algorithms & Performance", "description": "Best practices for algorithms and performance.", "preview": "Best practices for algorithms and performance.", "tags": ["algorithms", "performance"], "category": "principles", "url": "/principles/algorithms-performance/", "content": "algorithms & performance best practices for algorithms and performance. principles for clear algorithms and performance engineering: micro-benchmarks, memory discipline, and deterministic generators. algorithms performance"}, {"id": "33", "title": "Compiler Design", "description": "Optimization, portability and resilience for compilers.", "preview": "Optimization, portability and resilience for compilers.", "tags": ["compiler"], "category": "principles", "url": "/principles/compiler/", "content": "compiler design optimization, portability and resilience for compilers. guidelines for compiler design: clear ir boundaries, deterministic semantics, robust error reporting, and incremental compilation. compiler"}, {"id": "34", "title": "Data Pipelines", "description": "Time semantics, fault tolerance, etc. for batch/streaming.", "preview": "Time semantics, fault tolerance, etc. for batch/streaming.", "tags": ["data-pipelines", "etl", "streaming"], "category": "principles", "url": "/principles/data-pipelines/", "content": "data pipelines time semantics, fault tolerance, etc. for batch/streaming. principles for reliable batch and streaming pipelines: time semantics, fault tolerance, partitioning, observability, and reproducibility. data-pipelines etl streaming"}, {"id": "35", "title": "Extensibility & Plugin Architecture", "description": "Principles for plugin systems, stable APIs, and safe extensions.", "preview": "Principles for plugin systems, stable APIs, and safe extensions.", "tags": ["extensibility"], "category": "principles", "url": "/principles/extensibility/", "content": "extensibility & plugin architecture principles for plugin systems, stable apis, and safe extensions. guidelines for plugin architectures, stable apis, cross-language bindings, and safe extension points. extensibility"}, {"id": "36", "title": "Intervals & Constraints", "description": "Heuristics for choosing windowing strategies based on SLA tensions.", "preview": "Heuristics for choosing windowing strategies based on SLA tensions.", "tags": ["analytics", "data-pipelines", "streaming"], "category": "principles", "url": "/principles/interval-constraints/", "content": "intervals & constraints heuristics for choosing windowing strategies based on sla tensions. balancing latency (completeness) against verification (integrity) by choosing between speculative and pessimistic intervals. analytics data-pipelines streaming"}, {"id": "37", "title": "Media Analysis", "description": "Feature extraction and real-time handling for media data.", "preview": "Feature extraction and real-time handling for media data.", "tags": ["feature-extraction", "media"], "category": "principles", "url": "/principles/media-analysis/", "content": "media analysis feature extraction and real-time handling for media data. best practices for media feature extraction: stable schemas, streaming vs. batch modes, metadata preservation, and performance engineering. feature-extraction media"}, {"id": "38", "title": "Migration & Deduplication", "description": "Integrity and efficiency in migration/deduplication.", "preview": "Integrity and efficiency in migration/deduplication.", "tags": ["deduplication"], "category": "principles", "url": "/principles/migration-dedup/", "content": "migration & deduplication integrity and efficiency in migration/deduplication. practices for safe, idempotent, and efficient large-scale data migration and deduplication. deduplication"}, {"id": "39", "title": "ML Experiments", "description": "Reproducibility, resource-awareness, and lightweight MLOps.", "preview": "Reproducibility, resource-awareness, and lightweight MLOps.", "tags": ["ml"], "category": "principles", "url": "/principles/ml-experiments/", "content": "ml experiments reproducibility, resource-awareness, and lightweight mlops. practical guidance for reproducible, resource-aware ml experiments with lightweight mlops and deterministic evaluation. ml"}, {"id": "40", "title": "Monitoring & Observability", "description": "Metrics, logging, tracing, alerting for observable systems.", "preview": "Metrics, logging, tracing, alerting for observable systems.", "tags": ["monitoring"], "category": "principles", "url": "/principles/monitoring/", "content": "monitoring & observability metrics, logging, tracing, alerting for observable systems. best practices for metrics, structured logging, tracing, alerting, and slo-driven reliability. monitoring"}, {"id": "41", "title": "Networking & Services", "description": "API design, rate limiting, retries, and resilient service communication.", "preview": "API design, rate limiting, retries, and resilient service communication.", "tags": ["networking"], "category": "principles", "url": "/principles/networking-services/", "content": "networking & services api design, rate limiting, retries, and resilient service communication. practical guidance for api design, retries/backoff, rate limiting, connection pooling, and service resilience. networking"}, {"id": "42", "title": "Privacy & Agents", "description": "Designing safe, transparent, user-centric agents for sensitive data.", "preview": "Designing safe, transparent, user-centric agents for sensitive data.", "tags": ["privacy"], "category": "principles", "url": "/principles/privacy-agents/", "content": "privacy & agents designing safe, transparent, user-centric agents for sensitive data. privacy-first design rules for agents: local-first defaults, data minimization, consent, and auditable actions. privacy"}, {"id": "43", "title": "Retrieval & RAG", "description": "Building robust retrieval systems and RAG pipelines.", "preview": "Building robust retrieval systems and RAG pipelines.", "tags": ["retrieval"], "category": "principles", "url": "/principles/retrieval/", "content": "retrieval & rag building robust retrieval systems and rag pipelines. core principles for robust retrieval and rag: hybrid retrieval, embedding stability, evaluation, and privacy-aware indexing. retrieval"}, {"id": "44", "title": "SQL vs. NoSQL", "description": "Choosing the right database paradigm for your system.", "preview": "Choosing the right database paradigm for your system.", "tags": ["database"], "category": "principles", "url": "/principles/sql-vs-nosql/", "content": "sql vs. nosql choosing the right database paradigm for your system. a framework for deciding between sql (relational, acid) and nosql (distributed, flexible schema) databases based on data structure, scalability needs, and consistency requirements. database"}, {"id": "45", "title": "Web App", "description": "Designing apps based on 12-factor principles.", "preview": "Designing apps based on 12-factor principles.", "tags": ["extensibility"], "category": "principles", "url": "/principles/webapp/", "content": "web app designing apps based on 12-factor principles. guiding principles for production-ready web apps (12-factor-inspired): scaling, static/media handling, background work, ci/cd, and observability. extensibility"}], "documentCount": 46}