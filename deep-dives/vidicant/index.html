<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Vidicant - Systology</title><meta name=description content="Video processing for media pipelines."><link rel=canonical href=https://sambyte.net/systology/deep-dives/vidicant/><link rel=icon href=/systology/favicon.svg type=image/svg+xml><meta name=robots content="index, follow"><script>try{localStorage.getItem("theme")==="dark"&&document.documentElement.setAttribute("data-theme","dark")}catch{}</script><style>:root{--bg:#ffffff;--text:#0f1724}[data-theme=dark]{--bg:#0f1724;--text:#e2e8f0}html,body{background:var(--bg);color:var(--text)}</style><link rel=stylesheet href=/systology/css/styles.css><link rel=stylesheet href=/systology/css/syntax.css><link rel=stylesheet href=/systology/css/search.css></head><body><header class=site-header role=banner><div class="container header-inner"><a class=brand href=/systology/ aria-label=Systology><img src=/systology/favicon.svg alt class=logo-icon> Systology</a><nav class=site-nav role=navigation aria-label="Main navigation"><button class=search-toggle data-open-search aria-label=Search>
<svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="11" cy="11" r="8"/><line x1="21" y1="21" x2="16.65" y2="16.65"/></svg>
</button>
<button class=theme-toggle id=theme-toggle aria-label="Toggle dark mode">
<svg class="icon-moon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg class="icon-sun" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></nav></div></header><main id=content class="container prose"><article><header><div class=title-group><h1>Vidicant</h1><a class=link-pill href=https://github.com/huangsam/vidicant target=_blank rel=noopener title="View on GitHub">GH</a></div><h2>Video processing for media pipelines.</h2><div class=tags><span>Tags:</span>
<a class=badge href=/systology/tags/extensibility/>extensibility</a>
<a class=badge href=/systology/tags/feature-extraction/>feature-extraction</a>
<a class=badge href=/systology/tags/media/>media</a></div></header><section><h2 id=context--motivation>Context & Motivation</h2><p><strong>Context:</strong> <code>vidicant</code> is a cross-platform video and image feature extractor with a C++ core (OpenCV) and Python bindings via pybind11. It serves ML preprocessing pipelines by extracting motion, blur, color, and face features from media files, producing structured JSON output for downstream training and analysis.</p><p><strong>Motivation:</strong> After experimenting with xcode-trial, I wanted to create a cross-platform solution that could handle large-scale video preprocessing for ML pipelines, leveraging C++ for performance-critical tasks and Python for ease of use and integration.</p><h2 id=the-local-implementation>The Local Implementation</h2><ul><li><strong>Current Logic:</strong> C++ core uses OpenCV&rsquo;s <code>VideoCapture</code> (with FFmpeg backend) for sequential, file-based frame extraction and implements feature extractors: frame difference for motion detection, Laplacian variance for blur scoring, color k-means clustering for color analysis, and edge detection. For video files, it extracts frame count, FPS, resolution, duration, and motion detection metrics by reprocessing the file for each metric. Each analysis operation (motion score, dominant colors, scene detection) reopens the video and reads a limited sample (50-100 frames) for performance. pybind11 binds these as <code>process_image(path) -> dict</code> and <code>process_video(path, opts) -> dict</code> Python callables, handling type conversions (cv::Mat ‚Üî numpy array) at the boundary. An interface-based design (<code>IImageLoader</code>/<code>IVideoLoader</code>) provides clean abstraction over the processing pipeline. A CLI wraps the Python API for batch runs with glob patterns and outputs per-file JSON.</li><li><strong>C++/Python boundary design:</strong> pybind11 bindings are defined in a single <code>vidicant_py.cpp</code> that exposes the high-level functions‚Äînot the internal OpenCV types. Python callers never handle <code>cv::Mat</code> directly; the binding layer converts results to dicts and numpy arrays. Error handling maps C++ exceptions to Python exceptions with meaningful messages. This follows the principle of wrapping once, correctly, idiomatically‚Äîrather than exposing raw FFI.</li><li><strong>Bottleneck:</strong> IO-bound video decoding dominates processing time for large files (60%+ of wall-clock time for 1080p video) due to sequential file-based decoding and redundant reopens across multiple analysis passes. Memory usage is controlled by sampling only the first 50-100 frames per metric, avoiding full video decoding. Heuristic detectors (blur, motion) require per-dataset threshold tuning to avoid false positives‚Äîa hardcoded threshold calibrated on professional video flags most smartphone footage incorrectly.</li></ul><h2 id=comparison-to-industry-standards>Comparison to Industry Standards</h2><ul><li><strong>My Project:</strong> Lightweight cross-platform extractor prioritizing speed and Python UX. Single binary/wheel distribution with no cloud dependencies. Focused on preprocessing features for ML pipelines.</li><li><strong>Industry:</strong> Cloud video processing services (Google Video Intelligence, AWS Rekognition Video) offer managed pipelines with auto-scaling and broader model coverage, but require data egress, incur per-minute costs, and introduce privacy concerns for sensitive media. FFmpeg-based pipelines offer similar portability but lack integrated ML feature extraction.</li><li><strong>Gap Analysis:</strong> For large-scale production media pipelines, integrate with cloud object stores (S3/GCS) for input/output, add worker autoscaling (Kubernetes HPA on queue depth), and build a calibration suite for threshold tuning per-dataset. For on-prem deployments, focus on native acceleration (FFmpeg hardware decoders, CUDA where available).</li></ul><h2 id=risks--mitigations>Risks & Mitigations</h2><ul><li><strong>Platform packaging friction:</strong> CI builds wheels using scikit-build-core with CMake <code>FetchContent</code> for pybind11 integration. Provide cmake instructions as fallbacks for source builds. Test installation in CI on clean environments to catch missing native dependencies.</li><li><strong>False positives in detection:</strong> ship a calibration CLI that sweeps thresholds against a labeled dataset and recommends operating points. Document that default thresholds are tuned for professional video and must be recalibrated for other content types.</li><li><strong>ABI compatibility:</strong> pin OpenCV version in the build and statically link core dependencies into wheels to avoid system library conflicts. Run binary compatibility tests across target platforms in CI.</li><li><strong>pybind11 version drift:</strong> pin pybind11 version and test against minimum and latest supported Python versions (3.9‚Äì3.12) in the CI matrix.</li></ul></section><aside class=related><h3>Related</h3><ul><li><a href=/systology/deep-dives/beam-trial/>Beam Trial</a>
<span class=related-type><small class=label-tag>tag</small>
<small class=label-cat>category</small></span><br><small class=muted>Minimal Apache Beam Hello World in Java/Gradle demonstrating pipeline construction, transforms, and DirectRunner execution for learning Beam's core model.</small></li><li><a href=/systology/principles/extensibility/>Extensibility & Plugin Architecture</a>
<span class=related-type><small class=label-tag>tag</small></span><br><small class=muted>Guidelines for plugin architectures, stable APIs, cross-language bindings, and safe extension points.</small></li><li><a href=/systology/designs/cdn-media/>Global CDN Media Serving</a>
<span class=related-type><small class=label-tag>tag</small></span><br><small class=muted>CDN-backed media delivery architecture for low-latency, highly-available global media serving with background upload processing.</small></li><li><a href=/systology/deep-dives/grit/>Grit</a>
<span class=related-type><small class=label-tag>tag</small>
<small class=label-cat>category</small></span><br><small class=muted>From‚Äëscratch Git implementation in Rust focusing on object storage, performance, and plumbing/porcelain command compatibility.</small></li></ul></aside></article></main><footer class=site-footer role=contentinfo><div class="container footer-inner"><p class=copyright>&copy; 2026 Systology. All rights reserved.</p><div class=social-links><a href=https://github.com/huangsam target=_blank rel="noopener noreferrer" aria-label=GitHub><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon-github"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg>
</a><a href=http://linkedin.com/in/sambyte target=_blank rel="noopener noreferrer" aria-label=LinkedIn><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon-linkedin"><path d="M16 8a6 6 0 016 6v7h-4v-7a2 2 0 00-2-2 2 2 0 00-2 2v7h-4v-7a6 6 0 016-6z"/><rect x="2" y="9" width="4" height="12"/><circle cx="4" cy="4" r="2"/></svg></a></div></div></footer><div id=site-search-modal class=site-search-modal-container style=display:none><div class=site-search-overlay data-close-search></div><div class=site-search-modal><div class=site-search-header><div class=site-search-input-wrapper><span class=site-search-icon><svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="11" cy="11" r="8"/><line x1="21" y1="21" x2="16.65" y2="16.65"/></svg>
</span><input type=text class=site-search-input id=site-search-input placeholder="Search designs, principles, deep dives..." aria-label=Search autocomplete=off>
<button class=site-search-close data-close-search>&#215;</button></div></div><div class=site-search-body><div id=site-search-default class=site-search-default><div class=site-search-quick-links><a href=/systology/categories/ class=site-search-cta><span class=site-search-cta-icon>üìÇ</span>
<span class=site-search-cta-text>All Categories</span>
<span class=site-search-cta-arrow>‚Üí</span>
</a><a href=/systology/tags/ class=site-search-cta><span class=site-search-cta-icon>üè∑Ô∏è</span>
<span class=site-search-cta-text>All Tags</span>
<span class=site-search-cta-arrow>‚Üí</span></a></div></div><div id=site-search-results-list style=display:none></div></div></div></div><script>document.addEventListener("DOMContentLoaded",function(){let i=null,o=null;const t=document.getElementById("site-search-modal"),n=document.getElementById("site-search-input"),s=document.getElementById("site-search-default"),e=document.getElementById("site-search-results-list"),d=document.querySelectorAll("[data-close-search]"),h=document.querySelectorAll("[data-open-search]");if(!t)return;document.body.appendChild(t);let l=!1;function u(){if(l)return;fetch("/systology/search-index.json").then(e=>e.json()).then(e=>{i=e.documents,l=!0}).catch(e=>console.error("Failed to load search index:",e))}function r(){u(),t.style.display="flex",document.body.style.overflow="hidden",setTimeout(()=>{n.focus(),n.value.trim()?c(n.value):(s.style.display="block",e.style.display="none")},50)}function a(){t.style.display="none",document.body.style.overflow="",n.value="",e.innerHTML="",s.style.display="block",e.style.display="none"}h.forEach(e=>{e.addEventListener("click",e=>{e.preventDefault(),r()})}),d.forEach(e=>{e.addEventListener("click",a)});function c(t){if(!i)return;if(!t.trim()){s.style.display="block",e.style.display="none",e.innerHTML="";return}s.style.display="none",e.style.display="block",t=t.toLowerCase();const n=i.filter(e=>{const n=e.content.toLowerCase(),s=e.title.toLowerCase(),o=(e.tags||[]).join(" ").toLowerCase();return n.includes(t)||s.includes(t)}).slice(0,15);n.length===0?e.innerHTML='<p class="site-search-no-results">No results found.</p>':e.innerHTML=n.map(e=>`
        <a href="${e.url}" class="site-search-result">
          <div class="site-search-result-title">${e.title}</div>
          <div class="site-search-result-preview">${e.preview}</div>
          <div class="site-search-result-meta">
            <span class="site-search-badge-category">${e.category}</span>
            ${e.tags.map(e=>`<span class="site-search-badge">${e}</span>`).join("")}
          </div>
        </a>
      `).join("")}n.addEventListener("input",function(e){o&&clearTimeout(o),o=setTimeout(()=>{c(e.target.value)},300)}),document.addEventListener("keydown",function(e){(e.metaKey||e.ctrlKey)&&e.key==="k"&&(e.preventDefault(),t.style.display==="none"||t.style.display===""?r():a()),e.key==="Escape"&&t.style.display==="flex"&&a()})})</script><script>document.addEventListener("DOMContentLoaded",()=>{const t=document.querySelectorAll(".pseudocode-toggle"),n=document.querySelectorAll(".pseudocode-modal-close"),s=document.querySelectorAll(".pseudocode-modal-overlay");function o(e){const t=document.getElementById(e);if(!t)return;t.classList.add("active"),t.setAttribute("aria-hidden","false"),document.body.style.overflow="hidden";const n=t.querySelector(".pseudocode-modal-close");n&&n.focus()}function e(e){if(!e)return;e.classList.remove("active"),e.setAttribute("aria-hidden","true"),document.body.style.overflow="";const t=document.querySelector(`.pseudocode-toggle[aria-controls="${e.id}"]`);t&&t.focus()}t.forEach(e=>{e.addEventListener("click",()=>{const t=e.getAttribute("aria-controls");o(t)})}),n.forEach(t=>{t.addEventListener("click",t=>{const n=t.target.closest(".pseudocode-modal");e(n)})}),s.forEach(t=>{t.addEventListener("click",t=>{const n=t.target.closest(".pseudocode-modal");e(n)})}),document.addEventListener("keydown",t=>{if(t.key==="Escape"){const t=document.querySelector(".pseudocode-modal.active");t&&e(t)}})})</script><script src=/systology/js/mermaid.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){window.mermaid&&mermaid.initialize({startOnLoad:!0,theme:"base",securityLevel:"loose",themeVariables:{primaryColor:"#f3f4f6",primaryTextColor:"#0f1724",primaryBorderColor:"#2563eb",lineColor:"#6b7280",secondBkgColor:"#ffffff",tertiaryTextColor:"#6b7280",tertiaryColor:"#e6e9ee",noteBkgColor:"#f0f9ff",noteBorderColor:"#2563eb",fontFamily:'-apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif'},flowchart:{useMaxWidth:!0,curve:"linear"},sequence:{useMaxWidth:!0},gantt:{useWidth:0[0]}});var e=document.getElementById("theme-toggle");e&&e.addEventListener("click",function(){var e=document.documentElement.getAttribute("data-theme")==="dark";document.documentElement.setAttribute("data-theme",e?"":"dark");try{localStorage.setItem("theme",e?"light":"dark")}catch{}})})</script></body></html>